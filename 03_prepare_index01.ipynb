{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    HnswParameters,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile\n",
    ")\n",
    "import utils\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_azure_active_directory = False  # Set this flag to True if you are using Azure Active Directory\n",
    "if not use_azure_active_directory:\n",
    "    aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    aoai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "    aoai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=aoai_endpoint,\n",
    "        api_key=aoai_api_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "\n",
    "    embedding_model: str = \"text-embedding-ada-002\" \n",
    "\n",
    "    service_endpoint = os.environ[\"SEARCH_ENDPOINT\"] \n",
    "    index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "    key = os.environ[\"SEARCH_KEY\"]\n",
    "    credential = AzureKeyCredential(key)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE A JSON INPUT FILE FOR EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "├── pdf_dir  \n",
    "│&emsp; &emsp; ├── text_dir  \n",
    "│&emsp; &emsp; └── json_dir  \n",
    "│&emsp; &emsp; &emsp; &emsp; ├── docVectors.json(output1)  \n",
    "│&emsp; &emsp; &emsp; &emsp; └── docVectors2.json(output2)  \n",
    "this script  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = \"./pdf/text\"\n",
    "json_dir = \"./pdf/json\"\n",
    "json_file = \"docVectors.json\"\n",
    "category = \"manual\"\n",
    "embedded_file = \"docVectors2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a JSON file for Text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = []\n",
    "\n",
    "for i,fname in enumerate(next(os.walk(text_dir))[2]):\n",
    "    fpath = Path(os.path.join(text_dir, fname))\n",
    "    with open(fpath, \"rb\") as f:        \n",
    "        data = f.read().decode('utf-8')\n",
    "\n",
    "    file_contents.append(\n",
    "        {\n",
    "            \"id\": str(i),\n",
    "            \"title\": fpath.stem,\n",
    "            \"content\": data,\n",
    "            \"category\": category\n",
    "        }\n",
    "    )\n",
    "\n",
    "os.makedirs(json_dir, exist_ok=True)\n",
    "with open(os.path.join(json_dir, json_file), \"w\", encoding='utf-8') as f:\n",
    "    json.dump(file_contents, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a JSON file for Text and Embeddings input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_page_format(text: str, max_length: int = 7200) -> str:\n",
    "    content = json.loads(text)\n",
    "    content_str = json.dumps(content, ensure_ascii=False)\n",
    "\n",
    "    while len(content_str) > max_length:\n",
    "        k, v = content.popitem()\n",
    "        print(f\"Removed page {k}\")\n",
    "        content_str = json.dumps(content, ensure_ascii=False)\n",
    "        print(f\"New length: {len(content_str)}\")\n",
    "        if len(content) == 0:\n",
    "            print(\"Content is empty\")\n",
    "            exit(1)\n",
    "\n",
    "    out_doc = ''\n",
    "    for page in content:\n",
    "        out_doc += content[page]\n",
    "\n",
    "    return out_doc.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "# Read the text-sample.json\n",
    "with open(os.path.join(json_dir, json_file), 'r', encoding='utf-8') as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "# Generate embeddings for title and content fields \n",
    "for item in input_data:\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    title_embeddings = utils.generate_embeddings(title, embedding_model, client)\n",
    "    content_embeddings = utils.generate_embeddings(remove_page_format(content), embedding_model, client)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(os.path.join(json_dir, embedded_file), \"w\", encoding='utf-8') as f:\n",
    "    json.dump(input_data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE INDEX FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\"),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\"),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\",\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"default\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE AN INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSERT TEXT AND VECTOR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload some documents to the index\n",
    "with open(os.path.join(json_dir, embedded_file), 'r', encoding='utf-8') as file:  \n",
    "    documents = json.load(file)\n",
    "    \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM A HYBRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"ペットボトルの投棄方法は 1 から 9 番のどれですか？\"  \n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=utils.generate_embeddings(query, embedding_model, client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, \n",
    "    semantic_configuration_name=\"default\",\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling for Partial Content (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import HttpResponseError\n",
    "query = \"<query>\" \n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=utils.generate_embeddings(query, embedding_model, client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "try:\n",
    "    results = search_client.search(  \n",
    "        search_text=query,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"content\", \"category\"],\n",
    "        query_type=QueryType.SEMANTIC, \n",
    "        semantic_configuration_name=\"default\",\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=3\n",
    "    )\n",
    "\n",
    "    semantic_answers = results.get_answers()\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"Semantic Answer: {answer.text}\")\n",
    "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "        print(f\"Content: {result['content']}\")\n",
    "        print(f\"Category: {result['category']}\")\n",
    "\n",
    "        captions = result[\"@search.captions\"]\n",
    "        if captions:\n",
    "            caption = captions[0]\n",
    "            if caption.highlights:\n",
    "                print(f\"Caption: {caption.highlights}\\n\")\n",
    "            else:\n",
    "                print(f\"Caption: {caption.text}\\n\")\n",
    "                \n",
    "except HttpResponseError as e:\n",
    "    if \"Partial Content\" in str(e):\n",
    "        # Handle the 'Partial Content' case here\n",
    "        print(\"Received partial content. Fall back to vector/text hybrid...\\n\")\n",
    "        \n",
    "        results = search_client.search(  \n",
    "            search_text=query,  \n",
    "            vector_queries=[vector_query],\n",
    "            select=[\"title\", \"content\", \"category\"],\n",
    "            top=3\n",
    "        )\n",
    "\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"Reranker Score: {result['@search.score']}\")\n",
    "            print(f\"Content: {result['content']}\")\n",
    "            print(f\"Category: {result['category']}\")\n",
    "\n",
    "            captions = result[\"@search.captions\"]\n",
    "            if captions:\n",
    "                caption = captions[0]\n",
    "                if caption.highlights:\n",
    "                    print(f\"Caption: {caption.highlights}\\n\")\n",
    "                else:\n",
    "                    print(f\"Caption: {caption.text}\\n\")\n",
    "                    \n",
    "    else:\n",
    "        # Handle other HTTP errors\n",
    "        print(f\"An HTTP error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM A HYBRID MULTI-VECTOR SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タイトルと CONTENT をそれぞれベクトルに変換して検索する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"<query>\"  \n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query_1 = VectorizedQuery(vector=utils.generate_embeddings(query, embedding_model, client), k_nearest_neighbors=3, fields=\"titleVector\")\n",
    "vector_query_2 = VectorizedQuery(vector=utils.generate_embeddings(query, embedding_model, client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query_1, vector_query_2],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, \n",
    "    semantic_configuration_name=\"default\",\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF SCRIPT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
